{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21433bbc-a8e4-44f7-91d5-80f3eec2125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import base64\n",
    "import io\n",
    "import pylnk3\n",
    "import re\n",
    "import subprocess\n",
    "import uuid\n",
    "import time\n",
    "from pyironflow.pyironflow import PyironFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "026f84e2-f1eb-48db-a03a-a0d251ead5d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### sub_function_node: decide each time, overwrite or create a new folder.\n",
    "\n",
    "## every time a new directory, not overwrite\n",
    "@Workflow.wrap.as_function_node\n",
    "def generate_working_directory_keep(path, directory_name):\n",
    "    base = Path(path)\n",
    "    base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # find the biggest x in existed \"Python_marco_to_inp_x\" \n",
    "    existing = [d for d in base.iterdir() if d.is_dir() and d.name.startswith(directory_name)]\n",
    "    if existing:\n",
    "        numbers = [int(d.name.rsplit(\"_\", 1)[1]) for d in existing if \"_\" in d.name]\n",
    "        next_num = max(numbers) + 1\n",
    "    else:\n",
    "        next_num = 1\n",
    "    working_directory = base / f\"{directory_name}_{next_num}\"\n",
    "    working_directory.mkdir()\n",
    "    return working_directory\n",
    "\n",
    "\n",
    "## every time overwrite the directory\n",
    "@Workflow.wrap.as_function_node\n",
    "def generate_working_directory_overwrite(path, directory_name):\n",
    "    working_directory = Path(path) / directory_name\n",
    "    print(f\"[INFO] Working directory: {working_directory}\")\n",
    "\n",
    "    # \n",
    "    if not hasattr(generate_working_directory_overwrite, \"_already_initialized\"):\n",
    "        if working_directory.exists():\n",
    "            print(\"[INFO] (First run) Directory exists — deleting it and recreating.\")\n",
    "            shutil.rmtree(working_directory)  \n",
    "        working_directory.mkdir(parents=True, exist_ok=True)\n",
    "        generate_working_directory_overwrite._already_initialized = True\n",
    "        print(\"[INFO] (First run) Directory ready.\")\n",
    "    else:\n",
    "        # \n",
    "        if not working_directory.exists():\n",
    "            print(\"[INFO] (Later run) Directory missing — creating it again.\")\n",
    "            working_directory.mkdir(parents=True, exist_ok=True)\n",
    "        else:\n",
    "            print(\"[INFO] (Later run) Directory already exists — keep using it (no delete).\")\n",
    "\n",
    "    return working_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b0c165a-5ddc-46c7-b8e4-90deeaf99c7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: Geometry change\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def update_geometry_marco(\n",
    "                          original_abaqus_script,\n",
    "                          working_directory,\n",
    "                          plate_thickness: float = 2.0,  # plate thickness\n",
    "                          plate_length: float = 16.0, # plate length\n",
    "                          electrode_height: float = 10.0, # electrode height\n",
    "                          electrode_diameter: float = 20.0, # electrode diameter\n",
    "                          electrode_spherical_radius: float = 100.0, # electrode spherical radius\n",
    "                          Partition_position: float = 4.0,  # Partition position (Macro 1)\n",
    "                          Partition_position_1: float = 1.0, # Partition position 1 (Macro 3)\n",
    "                          Partition_position_2: float = 1.0 # Partition position 2 (Macro 3)\n",
    "                         ):\n",
    "\n",
    "    replacements = {\n",
    "                    \"dB\": plate_thickness,\n",
    "                    \"hB\": plate_length,\n",
    "                    \"hE\": electrode_height,\n",
    "                    \"dE\": electrode_diameter,\n",
    "                    \"R\": electrode_spherical_radius,\n",
    "                    \"pP\": Partition_position,\n",
    "                    \"pP1\": Partition_position_1,\n",
    "                    \"pP2\": Partition_position_2\n",
    "                   }\n",
    "\n",
    "    with open(original_abaqus_script, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    inside_macro_1_or_3 = False\n",
    "    updated_lines = []\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.match(r\"\\s*def\\s+Macro_1_Geometrie\\s*\\(\", line) or re.match(r\"\\s*def\\s+Macro_3_\", line):\n",
    "            inside_macro_1or3 = True\n",
    "        elif inside_macro_1_or_3 and re.match(r\"\\s*def\\s+\\w+\", line):\n",
    "            inside_macro_1_or_3 = False\n",
    "        if inside_macro_1_or_3:\n",
    "            stripped = line.strip()\n",
    "            matched = False\n",
    "            for var, val in replacements.items():\n",
    "                if stripped.startswith(f\"{var} =\") or stripped.startswith(f\"{var}=\"):\n",
    "                    indent = line[:line.find(var)]\n",
    "                    new_line = f\"{indent}{var} = {val}\\n\"\n",
    "                    updated_lines.append(new_line)\n",
    "                    matched = True\n",
    "                    break\n",
    "                if not matched:\n",
    "                    updated_lines.append(line)\n",
    "        else:\n",
    "            updated_lines.append(line)\n",
    "\n",
    "    base_name = os.path.splitext(original_abaqus_script)[0]\n",
    "    base_name = base_name + '_Geo_modified' \n",
    "    new_py_path = os.path.join(working_directory, base_name + \".py\")\n",
    "    new_txt_path = os.path.join(working_directory, base_name + \".txt\")\n",
    "    \n",
    "    # new abaqus script\n",
    "    with open(new_py_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(updated_lines)\n",
    "\n",
    "    # meanwhile a .txt, include the changed parameters\n",
    "    with open(new_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for var, val in replacements.items():\n",
    "            f.write(f\"{var} = {val}\\n\")\n",
    "            \n",
    "    return new_py_path, new_txt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4096eb9-2925-4aaf-b95f-b6d79eba3017",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: Abaqus marco script to inp \n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_abaqus_input(script_path, working_directory):\n",
    "    input_script = os.path.basename(script_path)   # Script name only (no path)\n",
    "    local_input_script = os.path.join(working_directory, input_script)   # Spell out the target path in the working directory\n",
    "    shutil.copy(script_path, local_input_script)\n",
    "    return local_input_script\n",
    "\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def run_in_abaqus(executable, script_path, working_directory):\n",
    "    ## Construct and run Abaqus on the command line\n",
    "    cmd = f'\"{executable}\" cae noGUI={script_path}'\n",
    "    subprocess.check_call(cmd, cwd=working_directory, shell=True)   ## Run the command in the working directory\n",
    "    \n",
    "    # print(working_directory)\n",
    "    files = os.listdir(working_directory)\n",
    "    # print(files)\n",
    "    \n",
    "    while True:\n",
    "        files = os.listdir(working_directory) # \"C:/Local_Dong/Projekt/AnAttAl/CAD/AnAttAl_CAD_OnlyWorkflow_demo/Python_marco_to_inp\")\n",
    "        # print(files)\n",
    "        cae_files = [f for f in files if f.lower().endswith('.cae')]\n",
    "        inp_files = [f for f in files if f.lower().endswith('.inp')]\n",
    "        if cae_files and inp_files:\n",
    "            print(f\"Finish, all files： {cae_files}, {inp_files}\\n\")\n",
    "            break\n",
    "    # if time.time() - start_time > timeout:\n",
    "    #     raise TimeoutError(\"check the code\")    \n",
    "    time.sleep(2)\n",
    "        \n",
    "    cae_path = os.path.join(working_directory, cae_files[0])\n",
    "    inp_path = os.path.join(working_directory, inp_files[0]) \n",
    "    \n",
    "    return {\"inp_path\":inp_path,\n",
    "            \"cae_path\":cae_path}\n",
    "\n",
    "# @Workflow.wrap.as_function_node\n",
    "# def collect_output(working_directory):\n",
    "#     print(working_directory)\n",
    "#     # start_time = time.time()\n",
    "#     # timeout = 30\n",
    "#     files = os.listdir(working_directory)\n",
    "#     print(files)\n",
    "#     while True:\n",
    "#         files = os.listdir(working_directory) # \"C:/Local_Dong/Projekt/AnAttAl/CAD/AnAttAl_CAD_OnlyWorkflow_demo/Python_marco_to_inp\")\n",
    "#         print(files)\n",
    "#         cae_files = [f for f in files if f.lower().endswith('.cae')]\n",
    "#         inp_files = [f for f in files if f.lower().endswith('.inp')]\n",
    "#         if cae_files and inp_files:\n",
    "#             print(f\"Finish, all files： {cae_files}, {inp_files}\\n\")\n",
    "#             break\n",
    "#     # if time.time() - start_time > timeout:\n",
    "#     #     raise TimeoutError(\"check the code\")    \n",
    "#     time.sleep(2)\n",
    "        \n",
    "#     cae_path = os.path.join(working_directory, cae_files[0])\n",
    "#     inp_path = os.path.join(working_directory, inp_files[0]) \n",
    "    \n",
    "#     return {\"cae_path\":cae_path, \n",
    "#             \"inp_path\":inp_path}\n",
    "    ## Since it is a job object, saved in HDF5, it can be called directly without return\n",
    "\n",
    "\n",
    "# @Workflow.wrap.as_function_node\n",
    "# def generate_working_directory(path):\n",
    "#     working_directory = Path(path) / \"Python_marco_to_inp\"\n",
    "#     print(f\"[INFO] Working directory: {working_directory}\")\n",
    "\n",
    "#     return working_directory\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"inp_path\", \"cae_path\")\n",
    "def export_inp_cae(macro, script_path, base_path, directory_name, executable=r\"C:\\SIMULIA\\Commands\\abq2018.bat\"):\n",
    "    # path = macro.as_path() # This gives you the path based on the workflow name\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.scripts = write_abaqus_input(script_path=script_path, \n",
    "                                       working_directory=macro.work_dir)\n",
    "    macro.inp_output = run_in_abaqus(executable=executable, \n",
    "                                     script_path=macro.scripts, \n",
    "                                     working_directory=macro.work_dir)\n",
    "    # macro.check = collect_output(working_directory=macro.work_dir)\n",
    "\n",
    "    # This is in principle not required, but it makes sure that the nodes are executed in the given order\n",
    "    # macro.work_dir >> macro.scripts >> macro.inp_output >> macro.\n",
    "    \n",
    "    return (macro.inp_output[\"inp_path\"],\n",
    "            macro.inp_output[\"cae_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "675889d9-705b-46b7-8f7f-32c252bd16ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: processing inp \n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_inp_input(script_path, inp_path, working_directory):\n",
    "        \n",
    "    ## Extract the file name and copy it to the current project directory.\n",
    "    # copy python script\n",
    "    input_script = os.path.basename(script_path)\n",
    "    local_script_path = os.path.join(working_directory, input_script)\n",
    "    shutil.copy(script_path, local_script_path)\n",
    "\n",
    "    # copy .inp file\n",
    "    input_path = os.path.basename(inp_path)\n",
    "    local_inp_path = os.path.join(working_directory, input_path)\n",
    "    shutil.copy(inp_path, local_inp_path)\n",
    "\n",
    "    return {\"script_path\":local_script_path, \n",
    "            \"inp_path\":local_inp_path}\n",
    "\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def run_in_python(executable, script_path, inp_path, working_directory):\n",
    "    ## Constructor commands: python script Input file\n",
    "    cmd = [str(executable), script_path, inp_path]\n",
    "    subprocess.check_call(cmd, cwd=working_directory)\n",
    "\n",
    "    all_txt_files = [f for f in os.listdir(working_directory) if f.lower().endswith(\".txt\")]\n",
    "    all_txt_files_path = [os.path.abspath(os.path.join(working_directory, f)) for f in os.listdir(working_directory) if f.endswith(\".txt\")]\n",
    "    print(f\"Finish, all files：{all_txt_files}\\n\")\n",
    "    \n",
    "    return {\"txt_paths\": all_txt_files_path} \n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"txt_paths\")\n",
    "def processing_inp(macro, script_path, inp_path, base_path, directory_name, executable=r\"python\"):\n",
    "    # path = macro.as_path() # This gives you the path based on the workflow name\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.scripts = write_inp_input(script_path=script_path, \n",
    "                                    inp_path=inp_path, \n",
    "                                    working_directory=macro.work_dir)\n",
    "    macro.processing_inp = run_in_python(executable=executable, \n",
    "                                         script_path=macro.scripts['script_path'], \n",
    "                                         inp_path=macro.scripts['inp_path'],\n",
    "                                         working_directory=macro.work_dir)\n",
    "    # macro.check = collect_output(working_directory=macro.work_dir)\n",
    "\n",
    "    return macro.processing_inp[\"txt_paths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81456e6d-5eb6-47a6-8ace-4ca53c24f39d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: in the furture, maybe we can read FAMOS data automated\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def FAMOS_input_txt(working_directory, input_txt_paths_von_FAMOS=[]):\n",
    "\n",
    "    # Copy all input txt files into working directory\n",
    "    local_txt_files = []\n",
    "    for txt_path in input_txt_paths_von_FAMOS:\n",
    "        txt_name = os.path.basename(txt_path)\n",
    "        dst_path = os.path.join(working_directory, txt_name)\n",
    "        txt_path = os.path.abspath(txt_path)\n",
    "        shutil.copy(txt_path, dst_path)\n",
    "        local_txt_files.append(dst_path)\n",
    "        \n",
    "    # print(local_txt_files)\n",
    "    \n",
    "    return {\"input_txt_set\": local_txt_files}\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"FAMOS_txt\")\n",
    "def FAMOS_Output(macro, base_path, directory_name, input_txt_paths_von_FAMOS=[]):\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)   \n",
    "    macro.FAMOS_input_txt = FAMOS_input_txt(working_directory=macro.work_dir,\n",
    "                                           input_txt_paths_von_FAMOS=input_txt_paths_von_FAMOS)\n",
    "    \n",
    "    return macro.FAMOS_input_txt[\"input_txt_set\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85407521-201e-4528-bf50-19fadceee110",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: activate fortran compiler und get simulation.exe\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_compiler_input(compiler_path, fortran_file_path, working_directory):\n",
    "    compiler_path = os.path.abspath(compiler_path)\n",
    "    fortran_file_path = os.path.abspath(fortran_file_path)\n",
    "\n",
    "    input_fortran_file = os.path.basename(fortran_file_path)   # Script name only (no path)\n",
    "    local_fortran_file_path = os.path.join(working_directory, input_fortran_file)   # Spell out the target path in the working directory\n",
    "    shutil.copy(fortran_file_path, local_fortran_file_path)\n",
    "\n",
    "    return {\"compiler_path\":compiler_path, \n",
    "            \"fortran_path\":local_fortran_file_path}\n",
    "    \n",
    "@Workflow.wrap.as_function_node\n",
    "def run_fortran_in_compiler(compiler_path, local_fortran_file_path, working_directory):\n",
    "    ## Parsing .lnk shortcuts (Windows)\n",
    "    with open(compiler_path, 'rb') as f:\n",
    "        lnk = pylnk3.parse(f)\n",
    "\n",
    "    raw_path = lnk.path.strip('\"')    # Executable path to which the shortcut points\n",
    "    raw_args = lnk.arguments.strip()    # Shortcut parameters\n",
    "\n",
    "    ## If .lnk points to cmd.exe, it is necessary to extract the .bat path from the parameter\n",
    "    if raw_path.lower().endswith(\"cmd.exe\"):\n",
    "        match = re.search(r'\"(?P<bat>C:.*?\\.bat)\"\\s*(?P<args>[^\"]*)', raw_args, re.IGNORECASE)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Unable to extract .bat file path from .lnk arguments with contents：{raw_args}\")\n",
    "        env_bat_path = match.group(\"bat\")\n",
    "        extra_args = match.group(\"args\")\n",
    "    else:\n",
    "        env_bat_path = raw_path\n",
    "        extra_args = raw_args\n",
    "\n",
    "    ## Constructing the ifort compilation command\n",
    "    # exe_name = self.output_exe or os.path.splitext(os.path.basename(self.local_fortran))[0] + \".exe\"\n",
    "    # exe_name = os.path.normpath(exe_name)\n",
    "    fortran_path = os.path.normpath(local_fortran_file_path)\n",
    "    compile_cmd = f'ifort \"{fortran_path}\"'\n",
    "\n",
    "    setup_cmd = f'call \"{env_bat_path}\" {extra_args} && {compile_cmd}'\n",
    "\n",
    "    # print(setup_cmd)\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            f'cmd /c \"{setup_cmd}\"',\n",
    "            cwd=working_directory,\n",
    "            shell=True,\n",
    "            check=True,\n",
    "            text=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "        print(\"compiler output:\\n\", result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"warning:\\n\", result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"error\")\n",
    "        print(\"stdout:\\n\", e.stdout)\n",
    "        print(\"stderr:\\n\", e.stderr)\n",
    "        raise\n",
    "\n",
    "    exe_files = [f for f in os.listdir(working_directory) if f.lower().endswith(\".exe\")]\n",
    "    if not exe_files:\n",
    "        raise FileNotFoundError(\".exe file not found in the working directory\")\n",
    "\n",
    "    exe_filename = exe_files[0]\n",
    "    exe_path = os.path.abspath(os.path.join(working_directory, exe_filename))\n",
    "    \n",
    "    print(f\"Finish, generated file: ['{exe_filename}']\\n\")\n",
    "    \n",
    "    return {\"fortran_exe_filename\": exe_filename,\n",
    "            \"exe_path\": exe_path}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"fortran_exe_filename\", \"exe_path\")\n",
    "def fortran_to_exe(macro, compiler_path, fortran_file_path, base_path, directory_name):\n",
    "    # path = macro.as_path() # This gives you the path based on the workflow name\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.fortran_file = write_compiler_input(compiler_path=compiler_path, \n",
    "                                              fortran_file_path=fortran_file_path, \n",
    "                                              working_directory=macro.work_dir)\n",
    "    macro.fortran_to_exe = run_fortran_in_compiler(compiler_path=macro.fortran_file[\"compiler_path\"], \n",
    "                                                   local_fortran_file_path=macro.fortran_file[\"fortran_path\"],\n",
    "                                                   working_directory=macro.work_dir)\n",
    "\n",
    "    return (macro.fortran_to_exe[\"fortran_exe_filename\"],\n",
    "            macro.fortran_to_exe[\"exe_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54afdbcc-79a9-4ce2-83fa-574d5eb3d40c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: running simulation.exe in compiler\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_running_exe_input(compiler_path, exe_path, working_directory, input_txt_paths_von_FAMOS=[], input_txt_paths_von_inp=[]):\n",
    "    compiler_path = os.path.abspath(compiler_path)\n",
    "    exe_path = os.path.abspath(exe_path)\n",
    "    \n",
    "    # Copy .exe to working directory\n",
    "    exe_filename = os.path.basename(exe_path)   # Script name only (no path)\n",
    "    local_exe_path = os.path.join(working_directory, exe_filename)   # Spell out the target path in the working directory\n",
    "    shutil.copy(exe_path, local_exe_path)\n",
    "\n",
    "    # Copy all input txt files into working directory\n",
    "    local_txt_files = []\n",
    "    for txt_path in input_txt_paths_von_FAMOS + input_txt_paths_von_inp:\n",
    "        txt_name = os.path.basename(txt_path)\n",
    "        dst_path = os.path.join(working_directory, txt_name)\n",
    "        txt_path = os.path.abspath(txt_path)\n",
    "        shutil.copy(txt_path, dst_path)\n",
    "        local_txt_files.append(dst_path)\n",
    "        \n",
    "    # print(local_txt_files)\n",
    "    \n",
    "    return {\"compiler_path\": compiler_path,\n",
    "            \"exe_filename\": exe_filename,\n",
    "            \"input_txt_set\": local_txt_files}\n",
    "\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def run_exe(compiler_path, exe_filename, working_directory):\n",
    "    with open(compiler_path, 'rb') as f:\n",
    "        lnk = pylnk3.parse(f)\n",
    "\n",
    "    raw_path = lnk.path.strip('\"')\n",
    "    raw_args = lnk.arguments.strip()\n",
    "\n",
    "    if raw_path.lower().endswith(\"cmd.exe\"):\n",
    "        match = re.search(r'\"(?P<bat>C:.*?\\.bat)\"\\s*(?P<args>[^\"]*)', raw_args, re.IGNORECASE)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Unable to extract .bat file path from .lnk arguments with contents：{raw_args}\")\n",
    "        env_bat_path = match.group(\"bat\")\n",
    "        extra_args = match.group(\"args\").strip('\"')\n",
    "    else:\n",
    "        env_bat_path = raw_path\n",
    "        extra_args = raw_args\n",
    "        \n",
    "    ## First call the compiler environment variable\n",
    "    ## Then cd to the working directory\n",
    "    ## Finally, execute the .exe file\n",
    "    run_cmd = f'call \"{env_bat_path}\" {extra_args} && cd /d \"{working_directory}\" && \"{exe_filename}\"'\n",
    "\n",
    "    # print(f\"\\n{run_cmd}\\n\")\n",
    "\n",
    "    # try:\n",
    "    #     result = subprocess.run(\n",
    "    #         f'cmd /c \"{run_cmd}\"',\n",
    "    #         cwd=working_directory,\n",
    "    #         shell=True,\n",
    "    #         check=True,\n",
    "    #         capture_output=True,\n",
    "    #         text=True\n",
    "    #     )\n",
    "    #     print(result.stdout)\n",
    "    #     print(result.stderr)\n",
    "        \n",
    "    # except subprocess.CalledProcessError as e:\n",
    "    #     print(\"error：\")\n",
    "    #     print(\"STDOUT:\\n\", e.stdout)\n",
    "    #     print(\"STDERR:\\n\", e.stderr)\n",
    "    #     raise\n",
    "    \n",
    "    result = subprocess.run(\n",
    "                            f'cmd /c \"{run_cmd}\"',\n",
    "                            cwd=working_directory,\n",
    "                            shell=True,\n",
    "                            # check=True,\n",
    "                            capture_output=True,\n",
    "                            text=True\n",
    "                            )\n",
    "    \n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "  \n",
    "    if result.returncode != 0:\n",
    "        stderr_lower = result.stderr.lower()\n",
    "        if \"end-of-file during read\" in stderr_lower and \"severe (24)\" in stderr_lower:\n",
    "            print(\"Warning: Fortran EOF read error (severe 24) detected.\")\n",
    "            print(\"Assuming simulation finished successfully, continuing...\\n\")\n",
    "        else:\n",
    "            print(\"Simulation failed with unknown error:\")\n",
    "            print(\"STDOUT:\\n\", result.stdout)\n",
    "            print(\"STDERR:\\n\", result.stderr)\n",
    "            raise subprocess.CalledProcessError(returncode=result.returncode,\n",
    "                                                cmd=run_cmd,\n",
    "                                                output=result.stdout,\n",
    "                                                stderr=result.stderr)  \n",
    "    \n",
    "    outputs = [f for f in os.listdir(working_directory) if f.endswith('.odb')]\n",
    "    print(f\"Simulation finished, odb files generated.\\n\")\n",
    "    \n",
    "    return {\"output_files\": [os.path.join(working_directory, f) for f in outputs],\n",
    "            \"outputs_files_directory\": [os.path.abspath(working_directory)]}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"output_files\",\"outputs_files_directory\")\n",
    "def running_exe_in_compiler(macro, compiler_path, exe_path, base_path, directory_name,\n",
    "                            input_txt_paths_von_FAMOS=[], input_txt_paths_von_inp=[]):\n",
    "    # path = macro.as_path() # This gives you the path based on the workflow name\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.write_exe_input = write_running_exe_input(compiler_path=compiler_path, \n",
    "                                                    exe_path=exe_path, \n",
    "                                                    working_directory=macro.work_dir,\n",
    "                                                    input_txt_paths_von_FAMOS=input_txt_paths_von_FAMOS,\n",
    "                                                    input_txt_paths_von_inp=input_txt_paths_von_inp)\n",
    "    macro.fortran_to_exe = run_exe(compiler_path=macro.write_exe_input[\"compiler_path\"], \n",
    "                                   exe_filename=macro.write_exe_input[\"exe_filename\"],\n",
    "                                   working_directory=macro.work_dir)\n",
    "\n",
    "    return (macro.fortran_to_exe[\"output_files\"],\n",
    "            macro.fortran_to_exe[\"outputs_files_directory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9f023bf-cc2f-46ee-86c6-1a932693b3e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: Pre-processing, find the files number and change the name of basic file\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def processing_mech_files(working_directory):\n",
    "    index = 250822\n",
    "    find_mech_file = f\"{index}_MECH_START.odb\"\n",
    "    replace_mech_file = f\"{index}_MECH_JOINED.odb\"\n",
    "\n",
    "    find_path = os.path.join(working_directory, find_mech_file)\n",
    "    replace_path = os.path.join(working_directory, replace_mech_file)\n",
    "\n",
    "    if os.path.exists(find_path):\n",
    "        shutil.copy(find_path, replace_path)\n",
    "        print(f\"aimed odb file found und renamed a new file\")\n",
    "    else:\n",
    "        print(f\"aimed odb file does not exist\")\n",
    "\n",
    "    \n",
    "    pattern = re.compile(rf\"{index}_WPS_MECH_RESTART(\\d+)\\.odb$\")\n",
    "    max_num = -1\n",
    "    for filename in os.listdir(working_directory):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            number = int(match.group(1))\n",
    "            if number > max_num:\n",
    "                max_num = number\n",
    "\n",
    "    if max_num >= 0:\n",
    "        print(f\"maximal RESTART file number is: {max_num}\")\n",
    "    else:\n",
    "        print(f\"does not find RESTART file, please check the directory\")\n",
    "\n",
    "    return {\"Initialization\":replace_path,\n",
    "            \"Iteration_number\":max_num}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"Initialization\",\"Iteration_number\")\n",
    "def Mechfiles_number_and_rename_Mechfile(macro, working_directory):\n",
    "\n",
    "    macro.preprocessing_mech_files = processing_mech_files(working_directory=working_directory)\n",
    "\n",
    "    return (macro.preprocessing_mech_files[\"Initialization\"],\n",
    "            macro.preprocessing_mech_files[\"Iteration_number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2009f92-2eab-4771-b36b-30fd301627fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: Pre-processing, change the parameter(files number) in join.for and running in compiler, in order to get modified join.exe\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_join_input(compiler_path, fortran_join_path, working_directory, Iteration_number):\n",
    "    compiler_path = os.path.abspath(compiler_path)\n",
    "    fortran_join_path = os.path.abspath(fortran_join_path)\n",
    "\n",
    "    input_fortran_file = os.path.basename(fortran_join_path)   # Script name only (no path)\n",
    "    local_fortran_join_path = os.path.join(working_directory, input_fortran_file)   # Spell out the target path in the working directory\n",
    "    shutil.copy(fortran_join_path, local_fortran_join_path)\n",
    "\n",
    "    with open(local_fortran_join_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    updated_lines = []\n",
    "    Iteration_number = int(Iteration_number)\n",
    "    for line in lines:\n",
    "        if \"do i=0,\" in line.lower():\n",
    "            parts = line.split(\"do i=0,\")\n",
    "            old_fisrt = parts[0]\n",
    "            # old_second = parts[1]\n",
    "            new = f\"{old_fisrt}do i=0, {Iteration_number}\\n\"\n",
    "            updated_lines.append(new)\n",
    "        else:\n",
    "            updated_lines.append(line)\n",
    "\n",
    "    with open(local_fortran_join_path, \"w\") as f:\n",
    "        f.writelines(updated_lines)\n",
    "    \n",
    "\n",
    "    return {\"compiler_path\":compiler_path, \n",
    "            \"fortran_join_path\":local_fortran_join_path}\n",
    "\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def run_fortran_join_in_compiler(compiler_path, local_fortran_join_path, working_directory):\n",
    "    ## Parsing .lnk shortcuts (Windows)\n",
    "    with open(compiler_path, 'rb') as f:\n",
    "        lnk = pylnk3.parse(f)\n",
    "\n",
    "    raw_path = lnk.path.strip('\"')    # Executable path to which the shortcut points\n",
    "    raw_args = lnk.arguments.strip()    # Shortcut parameters\n",
    "\n",
    "    ## If .lnk points to cmd.exe, it is necessary to extract the .bat path from the parameter\n",
    "    if raw_path.lower().endswith(\"cmd.exe\"):\n",
    "        match = re.search(r'\"(?P<bat>C:.*?\\.bat)\"\\s*(?P<args>[^\"]*)', raw_args, re.IGNORECASE)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Unable to extract .bat file path from .lnk arguments with contents：{raw_args}\")\n",
    "        env_bat_path = match.group(\"bat\")\n",
    "        extra_args = match.group(\"args\")\n",
    "    else:\n",
    "        env_bat_path = raw_path\n",
    "        extra_args = raw_args\n",
    "\n",
    "    ## Constructing the ifort compilation command\n",
    "    # exe_name = self.output_exe or os.path.splitext(os.path.basename(self.local_fortran))[0] + \".exe\"\n",
    "    # exe_name = os.path.normpath(exe_name)\n",
    "    fortran_path = os.path.normpath(local_fortran_join_path)\n",
    "    compile_cmd = f'ifort \"{fortran_path}\"'\n",
    "\n",
    "    setup_cmd = f'call \"{env_bat_path}\" {extra_args} && {compile_cmd}'\n",
    "\n",
    "    # print(setup_cmd)\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            f'cmd /c \"{setup_cmd}\"',\n",
    "            cwd=working_directory,\n",
    "            shell=True,\n",
    "            check=True,\n",
    "            text=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "        print(\"compiler output:\\n\", result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"warning:\\n\", result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"error\")\n",
    "        print(\"stdout:\\n\", e.stdout)\n",
    "        print(\"stderr:\\n\", e.stderr)\n",
    "        raise\n",
    "\n",
    "    exe_files = [f for f in os.listdir(working_directory) if f.lower().endswith(\".exe\")]\n",
    "    if not exe_files:\n",
    "        raise FileNotFoundError(\".exe file not found in the working directory\")\n",
    "\n",
    "    exe_filename = exe_files[0]\n",
    "    exe_path = os.path.abspath(os.path.join(working_directory, exe_filename))\n",
    "    \n",
    "    print(f\"Finish, generated file: ['{exe_filename}']\\n\")\n",
    "    \n",
    "    return {\"fortran_exe_filename\": exe_filename,\n",
    "            \"exe_path\": exe_path}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"fortran_join_exe_filename\", \"join_exe_path\")\n",
    "def fortran_join_to_exe(macro, compiler_path, fortran_join_path, base_path, directory_name, Iteration_number):\n",
    "    # path = macro.as_path() # This gives you the path based on the workflow name\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.fortran_join_file = write_join_input(compiler_path=compiler_path, \n",
    "                                               fortran_join_path=fortran_join_path, \n",
    "                                               working_directory=macro.work_dir,\n",
    "                                               Iteration_number=Iteration_number)\n",
    "    macro.fortran_join_to_exefile = run_fortran_join_in_compiler(compiler_path=macro.fortran_join_file[\"compiler_path\"], \n",
    "                                                             local_fortran_join_path=macro.fortran_join_file[\"fortran_join_path\"],\n",
    "                                                             working_directory=macro.work_dir)\n",
    "\n",
    "    return (macro.fortran_join_to_exefile[\"fortran_join_exe_filename\"],\n",
    "            macro.fortran_join_to_exefile[\"join_exe_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b2312ec-4584-4663-9409-d417bfe3e09d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: join all .odb files from simulation\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_join_exe_input(compiler_path, exe_path, Initial_file_path, working_directory, input_odb_paths):\n",
    "    compiler_path = os.path.abspath(compiler_path)\n",
    "    exe_path = os.path.abspath(exe_path)\n",
    "    Initial_file_path = os.path.abspath(Initial_file_path)\n",
    "    \n",
    "    # Copy .exe to working directory\n",
    "    exe_filename = os.path.basename(exe_path)   # Script name only (no path)\n",
    "    local_exe_path = os.path.join(working_directory, exe_filename)   # Spell out the target path in the working directory\n",
    "    shutil.copy(exe_path, local_exe_path)\n",
    "\n",
    "    # Copy initial.odb to working directory\n",
    "    initial_odb_filename = os.path.basename(Initial_file_path)   # Script name only (no path)\n",
    "    local_initial_odb_path = os.path.join(working_directory, initial_odb_filename)   # Spell out the target path in the working directory\n",
    "    shutil.copy(Initial_file_path, local_initial_odb_path)\n",
    "    \n",
    "    # Copy all input odb files into working directory\n",
    "    local_odb_files = []\n",
    "    for odb_path in input_odb_paths:\n",
    "        odb_name = os.path.basename(odb_path)\n",
    "        dst_path = os.path.join(working_directory, odb_name)\n",
    "        odb_path = os.path.abspath(txt_path)\n",
    "        shutil.copy(odb_path, dst_path)\n",
    "        local_odb_files.append(dst_path)\n",
    "        \n",
    "    # print(local_txt_files)\n",
    "    \n",
    "    return {\"compiler_path\": compiler_path,\n",
    "            \"join_exe_filename\": join_exe_filename,\n",
    "            \"input_odb_set\": local_odb_files}\n",
    "\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def run_join_exe(compiler_path, exe_filename, working_directory):\n",
    "    with open(compiler_path, 'rb') as f:\n",
    "        lnk = pylnk3.parse(f)\n",
    "\n",
    "    raw_path = lnk.path.strip('\"')\n",
    "    raw_args = lnk.arguments.strip()\n",
    "\n",
    "    if raw_path.lower().endswith(\"cmd.exe\"):\n",
    "        match = re.search(r'\"(?P<bat>C:.*?\\.bat)\"\\s*(?P<args>[^\"]*)', raw_args, re.IGNORECASE)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Unable to extract .bat file path from .lnk arguments with contents：{raw_args}\")\n",
    "        env_bat_path = match.group(\"bat\")\n",
    "        extra_args = match.group(\"args\").strip('\"')\n",
    "    else:\n",
    "        env_bat_path = raw_path\n",
    "        extra_args = raw_args\n",
    "        \n",
    "    ## First call the compiler environment variable\n",
    "    ## Then cd to the working directory\n",
    "    ## Finally, execute the .exe file\n",
    "    run_cmd = f'call \"{env_bat_path}\" {extra_args} && cd /d \"{working_directory}\" && \"{exe_filename}\"'\n",
    "\n",
    "    # print(f\"\\n{run_cmd}\\n\")\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            f'cmd /c \"{run_cmd}\"',\n",
    "            cwd=working_directory,\n",
    "            shell=True,\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        print(result.stdout)\n",
    "        print(result.stderr)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"error：\")\n",
    "        print(\"STDOUT:\\n\", e.stdout)\n",
    "        print(\"STDERR:\\n\", e.stderr)\n",
    "        raise\n",
    "\n",
    "    outputs = [f for f in os.listdir(working_directory) if f.endswith('.odb') and f == initial_odb_filename]\n",
    "    \n",
    "    print(f\"Joining finished, final odb files generated.\\n\")\n",
    "    \n",
    "    return {\"Final_odb_file_path\": [os.path.join(working_directory, f) for f in outputs]}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"Final_odb_file_path\")\n",
    "def running_join_exe_in_compiler(macro, compiler_path, exe_path, base_path, \n",
    "                                 Initial_file_path, directory_name, input_odb_paths):\n",
    "    # path = macro.as_path() # This gives you the path based on the workflow name\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.write_join_exe_input = write_join_exe_input(compiler_path=compiler_path, \n",
    "                                                      exe_path=exe_path, \n",
    "                                                      Initial_file_path=Initial_file_path,\n",
    "                                                      working_directory=macro.work_dir,\n",
    "                                                      input_odb_paths=input_odb_paths)\n",
    "    macro.fortran_join_to_exe = run_join_exe(compiler_path=macro.write_join_exe_input[\"compiler_path\"], \n",
    "                                             exe_filename=macro.write_join_exe_input[\"join_exe_filename\"],\n",
    "                                             working_directory=macro.work_dir)\n",
    "\n",
    "    return (macro.fortran_join_to_exe[\"Final_odb_file_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d0321ec-417e-490f-bfc1-819bf29e17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    wf = Workflow(\"Simulation_Workflow\")\n",
    "    wf.children.clear()\n",
    "    \n",
    "    project_path = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\AnAttAl_CAD_OnlyWorkflow_demo\"\n",
    "    abaqus_python_script = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\abaqusMacros.py\"\n",
    "    processing_inp_python_script = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\File_Programm2.py\"\n",
    "    fortran_compiler_path = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Compiler 16.0 Update 1 for Intel 64 Visual Studio 2015 environment.lnk\"\n",
    "    # fortran_file = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Testfall_1ms_Auskommentiert.for\" \n",
    "    fortran_file = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Testfall_1ms_Dyn5_a_a4.for\" \n",
    "    fortran_join_file = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\odbjoin.for\"\n",
    "    input_txts_FAMOS = [r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Stromverlauf.txt\",\n",
    "                        r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Kraftverlauf.txt\",\n",
    "                        r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Potentialverlauf.txt\"]\n",
    "    \n",
    "    wf.Update_Geo_Abaqus = update_geometry_marco(original_abaqus_script=abaqus_python_script,\n",
    "                                                 working_directory=project_path)\n",
    "    \n",
    "    wf.Abaqus_Output = export_inp_cae(script_path=wf.Update_Geo_Abaqus.outputs[\"new_py_path\"], \n",
    "                                      base_path=project_path,\n",
    "                                      directory_name=\"Python_marco_to_inp\")\n",
    "    \n",
    "    wf.Processing_inp = processing_inp(script_path=processing_inp_python_script, \n",
    "                                       inp_path=wf.Abaqus_Output.outputs[\"inp_path\"], \n",
    "                                       base_path=project_path,\n",
    "                                       directory_name=\"Python_marco_processing_inp\")\n",
    "\n",
    "    wf.FAMOS_Output = FAMOS_Output(base_path=project_path,\n",
    "                                   directory_name=\"FAMOS_Output\",\n",
    "                                   input_txt_paths_von_FAMOS=input_txts_FAMOS)\n",
    "    \n",
    "    wf.Fortran_Executable_File = fortran_to_exe(compiler_path=fortran_compiler_path, \n",
    "                                                fortran_file_path=fortran_file, \n",
    "                                                base_path=project_path, \n",
    "                                                directory_name=\"Fortran_to_simulation_exe\")\n",
    "    \n",
    "    wf.Executing_File_in_compiler = running_exe_in_compiler(compiler_path=fortran_compiler_path,\n",
    "                                                            exe_path=wf.Fortran_Executable_File.outputs[\"exe_path\"],\n",
    "                                                            base_path=project_path,\n",
    "                                                            directory_name=\"running_exe_in_compiler\",\n",
    "                                                            input_txt_paths_von_FAMOS=wf.FAMOS_Output.outputs[\"FAMOS_txt\"],\n",
    "                                                            input_txt_paths_von_inp=wf.Processing_inp.outputs[\"txt_paths\"])\n",
    "\n",
    "    wf.Number_of_Iterations_and_Initialization = Mechfiles_number_and_rename_Mechfile(working_directory=wf.Executing_File_in_compiler.outputs[\"outputs_files_directory\"])\n",
    "\n",
    "    wf.Fortran_join_Executable_File = fortran_join_to_exe(compiler_path=fortran_compiler_path,\n",
    "                                                          fortran_join_path=fortran_join_file,\n",
    "                                                          base_path=project_path,\n",
    "                                                          directory_name=\"Fortran_to_join_exe\",\n",
    "                                                          Iteration_number=wf.Number_of_Iterations_and_Initialization.outputs[\"Iteration_number\"])\n",
    "\n",
    "    wf.Executing_join_in_compiler = running_join_exe_in_compiler(compiler_path=fortran_compiler_path,\n",
    "                                                                 input_odb_paths=wf.Executing_File_in_compiler.outputs[\"output_files\"],\n",
    "                                                                 base_path=project_path,\n",
    "                                                                 directory_name=\"executing_join_exe\",\n",
    "                                                                 exe_path=wf.Fortran_join_Executable_File.outputs[\"join_exe_path\"],\n",
    "                                                                 Initial_file_path=wf.Number_of_Iterations_and_Initialization.outputs[\"Initialization\"])\n",
    "\n",
    "    wf.draw(size=(10,10))\n",
    "    # wf.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f2613ce-4da1-431c-9439-6f399413425c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2902a2abed6d485c9d67dfb3a8aa0f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Accordion(children=(VBox(children=(Button(button_style='info', description='Refresh', style=But…"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    pf = PyironFlow([wf])\n",
    "    pf.gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab9a9a-6dae-4d7b-ac8f-7a436cac2f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
