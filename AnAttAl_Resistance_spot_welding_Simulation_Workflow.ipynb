{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae2c404-1d35-4f3d-938e-88bacc9a6205",
   "metadata": {},
   "source": [
    "### AnAttAl Project – Integrated Simulation and Data Workflow for Resistance Spot Welding\n",
    "##### In this project, we use `pyiron` to establish a unified and reproducible workflow for `resistance spot welding simulations`. The workflow enables end-to-end execution within a single framework, avoiding fragmented and distributed processing steps.\n",
    "\n",
    "\n",
    "##### The core objective is to integrate commercial simulation software-`Abaqus`, user-defined `Fortran` subroutines, and experimentally recorded resistance spot welding data into one consistent workflow environment. Experimental input data are automatically imported, processed, and passed to the simulation chain, while intermediate and final output files generated at each stage are systematically stored and documented.\n",
    "\n",
    "\n",
    "##### By consolidating data handling, model execution, and post-processing within the pyiron workflow, AnAttAl provides a traceable and extensible infrastructure for simulation-driven analysis without manual intervention between individual tools. A dedicated `GUI` is implemented to interact with the workflow: it already includes a module for directly modifying geometric model parameters and provides one-click execution to run the simulation chain. The GUI is designed in a modular way, so that additional input components—such as material parameters or further process-related data—can be incorporated as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6e2f0d-c4a7-47df-873b-f81187a42c05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1614dd69-354f-42e9-b36c-f6c4eb5de242",
   "metadata": {},
   "source": [
    "#### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21433bbc-a8e4-44f7-91d5-80f3eec2125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_workflow import Workflow\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import base64\n",
    "import io\n",
    "import pylnk3\n",
    "import re\n",
    "import subprocess\n",
    "import uuid\n",
    "import time\n",
    "from pyironflow.pyironflow import PyironFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7933fe6c-3055-40b9-a780-9dbef150ff00",
   "metadata": {},
   "source": [
    "#### Working Directory Management\n",
    "##### This module controls how working directories are created for each workflow run. Two strategies are supported: \n",
    "1. create a new directory for every run (versioned folders). \n",
    "2. overwrite an existing directory on the first run and reuse it on subsequent runs.\n",
    "##### This ensures reproducibility and traceability of generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "026f84e2-f1eb-48db-a03a-a0d251ead5d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## every time a new directory, not overwrite\n",
    "@Workflow.wrap.as_function_node\n",
    "def generate_working_directory_keep(path, directory_name):\n",
    "    base = Path(path)\n",
    "    base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # find the biggest x in existed \"Python_marco_to_inp_x\" \n",
    "    existing = [d for d in base.iterdir() if d.is_dir() and d.name.startswith(directory_name)]\n",
    "    if existing:\n",
    "        numbers = [int(d.name.rsplit(\"_\", 1)[1]) for d in existing if \"_\" in d.name]\n",
    "        next_num = max(numbers) + 1\n",
    "    else:\n",
    "        next_num = 1\n",
    "    working_directory = base / f\"{directory_name}_{next_num}\"\n",
    "    working_directory.mkdir()\n",
    "    return working_directory\n",
    "\n",
    "\n",
    "## every time overwrite the directory\n",
    "@Workflow.wrap.as_function_node\n",
    "def generate_working_directory_overwrite(path, directory_name):\n",
    "    working_directory = Path(path) / directory_name\n",
    "    print(f\"[INFO] Working directory: {working_directory}\")\n",
    "\n",
    "    # \n",
    "    if not hasattr(generate_working_directory_overwrite, \"_already_initialized\"):\n",
    "        if working_directory.exists():\n",
    "            print(\"[INFO] (First run) Directory exists — deleting it and recreating.\")\n",
    "            shutil.rmtree(working_directory)  \n",
    "        working_directory.mkdir(parents=True, exist_ok=True)\n",
    "        generate_working_directory_overwrite._already_initialized = True\n",
    "        print(\"[INFO] (First run) Directory ready.\")\n",
    "    else:\n",
    "        # \n",
    "        if not working_directory.exists():\n",
    "            print(\"[INFO] (Later run) Directory missing — creating it again.\")\n",
    "            working_directory.mkdir(parents=True, exist_ok=True)\n",
    "        else:\n",
    "            print(\"[INFO] (Later run) Directory already exists — keep using it (no delete).\")\n",
    "\n",
    "    return working_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17ca7f-3499-4194-b490-09b72b69ec5f",
   "metadata": {},
   "source": [
    "#### Geometry Update Function\n",
    "\n",
    "##### This function automatically updates geometric parameters in the original Abaqus script and generates a modified version for the current workflow run.\n",
    "\n",
    "##### The procedure works as follows:\n",
    "\n",
    "1. The original Abaqus script is read line by line.\n",
    "\n",
    "2. Only the geometry-related functions (Macro_1_ and Macro_3_) are targeted.\n",
    "\n",
    "3. Predefined geometric parameters (e.g., plate thickness, electrode dimensions, partition positions) are replaced with user-defined values.\n",
    "\n",
    "4. A new modified Python script is created instead of overwriting the original file.\n",
    "\n",
    "5. A separate .txt file is generated to record all updated parameters.\n",
    "\n",
    "##### This approach ensures:\n",
    "\n",
    "- Reproducibility of geometry configurations\n",
    "\n",
    "- Traceability of parameter changes for each workflow run\n",
    "\n",
    "- Preservation of the original Abaqus script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b0c165a-5ddc-46c7-b8e4-90deeaf99c7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@Workflow.wrap.as_function_node\n",
    "def update_geometry_marco(\n",
    "                          original_abaqus_script,\n",
    "                          working_directory,\n",
    "                          plate_thickness: float = 2.0,  # plate thickness\n",
    "                          plate_length: float = 16.0, # plate length\n",
    "                          electrode_height: float = 10.0, # electrode height\n",
    "                          electrode_diameter: float = 20.0, # electrode diameter\n",
    "                          electrode_spherical_radius: float = 100.0, # electrode spherical radius\n",
    "                          Partition_position: float = 4.0,  # Partition position (Macro 1)\n",
    "                          Partition_position_1: float = 1.0, # Partition position 1 (Macro 3)\n",
    "                          Partition_position_2: float = 1.0 # Partition position 2 (Macro 3)\n",
    "                         ):\n",
    "\n",
    "    replacements = {\n",
    "                    \"dB\": plate_thickness,\n",
    "                    \"hB\": plate_length,\n",
    "                    \"hE\": electrode_height,\n",
    "                    \"dE\": electrode_diameter,\n",
    "                    \"R\": electrode_spherical_radius,\n",
    "                    \"pP\": Partition_position,\n",
    "                    \"pP1\": Partition_position_1,\n",
    "                    \"pP2\": Partition_position_2\n",
    "                   }\n",
    "\n",
    "    with open(original_abaqus_script, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    inside_macro_1_or_3 = False\n",
    "    updated_lines = []\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.match(r\"\\s*def\\s+Macro_1_Geometrie\\s*\\(\", line) or re.match(r\"\\s*def\\s+Macro_3_\", line):\n",
    "            inside_macro_1or3 = True\n",
    "        elif inside_macro_1_or_3 and re.match(r\"\\s*def\\s+\\w+\", line):\n",
    "            inside_macro_1_or_3 = False\n",
    "        if inside_macro_1_or_3:\n",
    "            stripped = line.strip()\n",
    "            matched = False\n",
    "            for var, val in replacements.items():\n",
    "                if stripped.startswith(f\"{var} =\") or stripped.startswith(f\"{var}=\"):\n",
    "                    indent = line[:line.find(var)]\n",
    "                    new_line = f\"{indent}{var} = {val}\\n\"\n",
    "                    updated_lines.append(new_line)\n",
    "                    matched = True\n",
    "                    break\n",
    "                if not matched:\n",
    "                    updated_lines.append(line)\n",
    "        else:\n",
    "            updated_lines.append(line)\n",
    "\n",
    "    base_name = os.path.splitext(original_abaqus_script)[0]\n",
    "    base_name = base_name + '_Geo_modified' \n",
    "    new_py_path = os.path.join(working_directory, base_name + \".py\")\n",
    "    new_txt_path = os.path.join(working_directory, base_name + \".txt\")\n",
    "    \n",
    "    # new abaqus script\n",
    "    with open(new_py_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(updated_lines)\n",
    "\n",
    "    # meanwhile a .txt, include the changed parameters\n",
    "    with open(new_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for var, val in replacements.items():\n",
    "            f.write(f\"{var} = {val}\\n\")\n",
    "            \n",
    "    return new_py_path, new_txt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0a372-b6c7-4acb-a0a1-3585062b30b2",
   "metadata": {},
   "source": [
    "#### Abaqus Macro Execution and .inp Export\n",
    "\n",
    "##### This module automates the execution of an Abaqus macro script and exports the resulting `.inp` and `.cae` files within a controlled workflow environment.\n",
    "\n",
    "##### The procedure is:\n",
    "\n",
    "1. Copy the Abaqus macro script into a dedicated working directory.\n",
    "\n",
    "2. Execute Abaqus in noGUI mode via command line.\n",
    "\n",
    "3. Monitor the directory until both .cae and .inp files are generated.\n",
    "\n",
    "4. Return the paths of the generated files to the workflow.\n",
    "\n",
    "##### The `export_inp_cae` macro node orchestrates the entire process, ensuring isolated execution, structured file management, and reproducible simulation output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4096eb9-2925-4aaf-b95f-b6d79eba3017",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: Abaqus marco script to inp \n",
    "@Workflow.wrap.as_function_node\n",
    "def write_abaqus_input(script_path, working_directory):\n",
    "    input_script = os.path.basename(script_path)   # Script name only (no path)\n",
    "    local_input_script = os.path.join(working_directory, input_script)   # Spell out the target path in the working directory\n",
    "    shutil.copy(script_path, local_input_script)\n",
    "    return local_input_script\n",
    "\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def run_in_abaqus(executable, script_path, working_directory):\n",
    "    ## Construct and run Abaqus on the command line\n",
    "    cmd = f'\"{executable}\" cae noGUI={script_path}'\n",
    "    subprocess.check_call(cmd, cwd=working_directory, shell=True)   ## Run the command in the working directory\n",
    "    files = os.listdir(working_directory)\n",
    " \n",
    "    \n",
    "    while True:\n",
    "        files = os.listdir(working_directory)\n",
    "        # print(files)\n",
    "        cae_files = [f for f in files if f.lower().endswith('.cae')]\n",
    "        inp_files = [f for f in files if f.lower().endswith('.inp')]\n",
    "        if cae_files and inp_files:\n",
    "            print(f\"Finish, all files： {cae_files}, {inp_files}\\n\")\n",
    "            break\n",
    "    # if time.time() - start_time > timeout:\n",
    "    #     raise TimeoutError(\"check the code\")    \n",
    "    time.sleep(2)\n",
    "        \n",
    "    cae_path = os.path.join(working_directory, cae_files[0])\n",
    "    inp_path = os.path.join(working_directory, inp_files[0]) \n",
    "    \n",
    "    return {\"inp_path\":inp_path,\n",
    "            \"cae_path\":cae_path}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"inp_path\", \"cae_path\")\n",
    "def export_inp_cae(macro, script_path, base_path, directory_name, executable=r\"C:\\SIMULIA\\Commands\\abq2018.bat\"):\n",
    "    # path = macro.as_path() # This gives you the path based on the workflow name\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.scripts = write_abaqus_input(script_path=script_path, \n",
    "                                       working_directory=macro.work_dir)\n",
    "    macro.inp_output = run_in_abaqus(executable=executable, \n",
    "                                     script_path=macro.scripts, \n",
    "                                     working_directory=macro.work_dir)\n",
    "\n",
    "    return (macro.inp_output[\"inp_path\"],\n",
    "            macro.inp_output[\"cae_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647a232-b907-4a38-837a-ed25fdbf6b2c",
   "metadata": {},
   "source": [
    "#### .inp Processing\n",
    "##### This module processes the generated .inp file using an external Python script.\n",
    "##### The script parses the input file to extract relevant information, such as:\n",
    "1. Node definitions\n",
    "\n",
    "2. Element data\n",
    "\n",
    "3. Material properties\n",
    "\n",
    "4. Other model parameters\n",
    "\n",
    "##### The extracted data are written into structured `.txt` files for further analysis within the workflow.\n",
    "\n",
    "##### Execution is performed in an isolated working directory to ensure reproducibility and clean file management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "675889d9-705b-46b7-8f7f-32c252bd16ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: processing inp \n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_inp_input(script_path, inp_path, working_directory):\n",
    "        \n",
    "    input_script = os.path.basename(script_path)\n",
    "    local_script_path = os.path.join(working_directory, input_script)\n",
    "    shutil.copy(script_path, local_script_path)\n",
    "\n",
    "    input_path = os.path.basename(inp_path)\n",
    "    local_inp_path = os.path.join(working_directory, input_path)\n",
    "    shutil.copy(inp_path, local_inp_path)\n",
    "\n",
    "    return {\"script_path\":local_script_path, \n",
    "            \"inp_path\":local_inp_path}\n",
    "\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def run_in_python(executable, script_path, inp_path, working_directory):\n",
    "    cmd = [str(executable), script_path, inp_path]\n",
    "    subprocess.check_call(cmd, cwd=working_directory)\n",
    "\n",
    "    all_txt_files = [f for f in os.listdir(working_directory) if f.lower().endswith(\".txt\")]\n",
    "    all_txt_files_path = [os.path.abspath(os.path.join(working_directory, f)) for f in os.listdir(working_directory) if f.endswith(\".txt\")]\n",
    "    print(f\"Finish, all files：{all_txt_files}\\n\")\n",
    "    \n",
    "    return {\"txt_paths\": all_txt_files_path} \n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"txt_paths\")\n",
    "def processing_inp(macro, script_path, inp_path, base_path, directory_name, executable=r\"python\"):\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.scripts = write_inp_input(script_path=script_path, \n",
    "                                    inp_path=inp_path, \n",
    "                                    working_directory=macro.work_dir)\n",
    "    macro.processing_inp = run_in_python(executable=executable, \n",
    "                                         script_path=macro.scripts['script_path'], \n",
    "                                         inp_path=macro.scripts['inp_path'],\n",
    "                                         working_directory=macro.work_dir)\n",
    "\n",
    "    return macro.processing_inp[\"txt_paths\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f365f3e-13ac-41d0-904a-d888af2656c6",
   "metadata": {},
   "source": [
    "#### Import FAMOS Welding Data\n",
    "\n",
    "##### This module imports welding process data exported from FAMOS (.txt files) into the workflow.\n",
    "\n",
    "##### The files are copied into the working directory and their local paths are returned for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81456e6d-5eb6-47a6-8ace-4ca53c24f39d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@Workflow.wrap.as_function_node\n",
    "def FAMOS_input_txt(working_directory, input_txt_paths_von_FAMOS=[]):\n",
    "\n",
    "    # Copy all input txt files into working directory\n",
    "    local_txt_files = []\n",
    "    for txt_path in input_txt_paths_von_FAMOS:\n",
    "        txt_name = os.path.basename(txt_path)\n",
    "        dst_path = os.path.join(working_directory, txt_name)\n",
    "        txt_path = os.path.abspath(txt_path)\n",
    "        shutil.copy(txt_path, dst_path)\n",
    "        local_txt_files.append(dst_path)\n",
    "        \n",
    "    # print(local_txt_files)\n",
    "    \n",
    "    return {\"input_txt_set\": local_txt_files}\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"FAMOS_txt\")\n",
    "def FAMOS_Output(macro, base_path, directory_name, input_txt_paths_von_FAMOS=[]):\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)   \n",
    "    macro.FAMOS_input_txt = FAMOS_input_txt(working_directory=macro.work_dir,\n",
    "                                           input_txt_paths_von_FAMOS=input_txt_paths_von_FAMOS)\n",
    "    \n",
    "    return macro.FAMOS_input_txt[\"input_txt_set\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f9f615-956e-4b59-8319-898ce631121c",
   "metadata": {},
   "source": [
    "#### Fortran Compilation to Executable\n",
    "\n",
    "##### This module compiles a Fortran source file into a simulation `.exe` within the workflow:\n",
    "\n",
    "1. Copy the Fortran source file into a dedicated working directory.\n",
    "\n",
    "2. Resolve the compiler environment from a Windows .lnk shortcut (extracting the underlying .bat setup if needed).\n",
    "\n",
    "3. Activate the compiler environment and compile the file (e.g., via ifort).\n",
    "\n",
    "4. Detect the generated .exe in the working directory and return its filename and absolute path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85407521-201e-4528-bf50-19fadceee110",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: activate fortran compiler und get simulation.exe\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_compiler_input(compiler_path, fortran_file_path, working_directory):\n",
    "    compiler_path = os.path.abspath(compiler_path)\n",
    "    fortran_file_path = os.path.abspath(fortran_file_path)\n",
    "\n",
    "    input_fortran_file = os.path.basename(fortran_file_path)   # Script name only (no path)\n",
    "    local_fortran_file_path = os.path.join(working_directory, input_fortran_file)   # Spell out the target path in the working directory\n",
    "    shutil.copy(fortran_file_path, local_fortran_file_path)\n",
    "\n",
    "    return {\"compiler_path\":compiler_path, \n",
    "            \"fortran_path\":local_fortran_file_path}\n",
    "    \n",
    "@Workflow.wrap.as_function_node\n",
    "def run_fortran_in_compiler(compiler_path, local_fortran_file_path, working_directory):\n",
    "    ## Parsing .lnk shortcuts (Windows)\n",
    "    with open(compiler_path, 'rb') as f:\n",
    "        lnk = pylnk3.parse(f)\n",
    "\n",
    "    raw_path = lnk.path.strip('\"')    # Executable path to which the shortcut points\n",
    "    raw_args = lnk.arguments.strip()    # Shortcut parameters\n",
    "\n",
    "    ## If .lnk points to cmd.exe, it is necessary to extract the .bat path from the parameter\n",
    "    if raw_path.lower().endswith(\"cmd.exe\"):\n",
    "        match = re.search(r'\"(?P<bat>C:.*?\\.bat)\"\\s*(?P<args>[^\"]*)', raw_args, re.IGNORECASE)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Unable to extract .bat file path from .lnk arguments with contents：{raw_args}\")\n",
    "        env_bat_path = match.group(\"bat\")\n",
    "        extra_args = match.group(\"args\")\n",
    "    else:\n",
    "        env_bat_path = raw_path\n",
    "        extra_args = raw_args\n",
    "\n",
    "    fortran_path = os.path.normpath(local_fortran_file_path)\n",
    "    compile_cmd = f'ifort \"{fortran_path}\"'\n",
    "    setup_cmd = f'call \"{env_bat_path}\" {extra_args} && {compile_cmd}'\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            f'cmd /c \"{setup_cmd}\"',\n",
    "            cwd=working_directory,\n",
    "            shell=True,\n",
    "            check=True,\n",
    "            text=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "        print(\"compiler output:\\n\", result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"warning:\\n\", result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"error\")\n",
    "        print(\"stdout:\\n\", e.stdout)\n",
    "        print(\"stderr:\\n\", e.stderr)\n",
    "        raise\n",
    "\n",
    "    exe_files = [f for f in os.listdir(working_directory) if f.lower().endswith(\".exe\")]\n",
    "    if not exe_files:\n",
    "        raise FileNotFoundError(\".exe file not found in the working directory\")\n",
    "\n",
    "    exe_filename = exe_files[0]\n",
    "    exe_path = os.path.abspath(os.path.join(working_directory, exe_filename))\n",
    "    \n",
    "    print(f\"Finish, generated file: ['{exe_filename}']\\n\")\n",
    "    \n",
    "    return {\"fortran_exe_filename\": exe_filename,\n",
    "            \"exe_path\": exe_path}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"fortran_exe_filename\", \"exe_path\")\n",
    "def fortran_to_exe(macro, compiler_path, fortran_file_path, base_path, directory_name):\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.fortran_file = write_compiler_input(compiler_path=compiler_path, \n",
    "                                              fortran_file_path=fortran_file_path, \n",
    "                                              working_directory=macro.work_dir)\n",
    "    macro.fortran_to_exe = run_fortran_in_compiler(compiler_path=macro.fortran_file[\"compiler_path\"], \n",
    "                                                   local_fortran_file_path=macro.fortran_file[\"fortran_path\"],\n",
    "                                                   working_directory=macro.work_dir)\n",
    "\n",
    "    return (macro.fortran_to_exe[\"fortran_exe_filename\"],\n",
    "            macro.fortran_to_exe[\"exe_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614f3ad-a74a-415d-b286-84de0013d337",
   "metadata": {},
   "source": [
    "#### Run Simulation Executable\n",
    "\n",
    "##### This module runs the compiled simulation .exe within the compiler environment and collects the simulation outputs:\n",
    "\n",
    "1. Copy the simulation .exe and all required input .txt files (from FAMOS and .inp processing) into a dedicated working directory.\n",
    "\n",
    "2. Activate the compiler environment via the provided Windows .lnk (resolving the underlying .bat setup if required).\n",
    "\n",
    "3. Execute the .exe in the working directory.\n",
    "\n",
    "4. Detect generated .odb output files and return their paths (and the output directory) to the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54afdbcc-79a9-4ce2-83fa-574d5eb3d40c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: running simulation.exe in compiler\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_running_exe_input(compiler_path, exe_path, working_directory, input_txt_paths_von_FAMOS=[], input_txt_paths_von_inp=[]):\n",
    "    compiler_path = os.path.abspath(compiler_path)\n",
    "    exe_path = os.path.abspath(exe_path)\n",
    "    \n",
    "    # Copy .exe to working directory\n",
    "    exe_filename = os.path.basename(exe_path)   # Script name only (no path)\n",
    "    local_exe_path = os.path.join(working_directory, exe_filename)   # Spell out the target path in the working directory\n",
    "    shutil.copy(exe_path, local_exe_path)\n",
    "\n",
    "    # Copy all input txt files into working directory\n",
    "    local_txt_files = []\n",
    "    for txt_path in input_txt_paths_von_FAMOS + input_txt_paths_von_inp:\n",
    "        txt_name = os.path.basename(txt_path)\n",
    "        dst_path = os.path.join(working_directory, txt_name)\n",
    "        txt_path = os.path.abspath(txt_path)\n",
    "        shutil.copy(txt_path, dst_path)\n",
    "        local_txt_files.append(dst_path)\n",
    "        \n",
    "    # print(local_txt_files)\n",
    "    \n",
    "    return {\"compiler_path\": compiler_path,\n",
    "            \"exe_filename\": exe_filename,\n",
    "            \"input_txt_set\": local_txt_files}\n",
    "\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def run_exe(compiler_path, exe_filename, working_directory):\n",
    "    with open(compiler_path, 'rb') as f:\n",
    "        lnk = pylnk3.parse(f)\n",
    "\n",
    "    raw_path = lnk.path.strip('\"')\n",
    "    raw_args = lnk.arguments.strip()\n",
    "\n",
    "    if raw_path.lower().endswith(\"cmd.exe\"):\n",
    "        match = re.search(r'\"(?P<bat>C:.*?\\.bat)\"\\s*(?P<args>[^\"]*)', raw_args, re.IGNORECASE)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Unable to extract .bat file path from .lnk arguments with contents：{raw_args}\")\n",
    "        env_bat_path = match.group(\"bat\")\n",
    "        extra_args = match.group(\"args\").strip('\"')\n",
    "    else:\n",
    "        env_bat_path = raw_path\n",
    "        extra_args = raw_args\n",
    "        \n",
    "    ## First call the compiler environment variable\n",
    "    ## Then cd to the working directory\n",
    "    ## Finally, execute the .exe file\n",
    "    run_cmd = f'call \"{env_bat_path}\" {extra_args} && cd /d \"{working_directory}\" && \"{exe_filename}\"'\n",
    "    \n",
    "    result = subprocess.run(\n",
    "                            f'cmd /c \"{run_cmd}\"',\n",
    "                            cwd=working_directory,\n",
    "                            shell=True,\n",
    "                            # check=True,\n",
    "                            capture_output=True,\n",
    "                            text=True\n",
    "                            )\n",
    "    \n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "  \n",
    "    if result.returncode != 0:\n",
    "        stderr_lower = result.stderr.lower()\n",
    "        if \"end-of-file during read\" in stderr_lower and \"severe (24)\" in stderr_lower:\n",
    "            print(\"Warning: Fortran EOF read error (severe 24) detected.\")\n",
    "            print(\"Assuming simulation finished successfully, continuing...\\n\")\n",
    "        else:\n",
    "            print(\"Simulation failed with unknown error:\")\n",
    "            print(\"STDOUT:\\n\", result.stdout)\n",
    "            print(\"STDERR:\\n\", result.stderr)\n",
    "            raise subprocess.CalledProcessError(returncode=result.returncode,\n",
    "                                                cmd=run_cmd,\n",
    "                                                output=result.stdout,\n",
    "                                                stderr=result.stderr)  \n",
    "    \n",
    "    outputs = [f for f in os.listdir(working_directory) if f.endswith('.odb')]\n",
    "    print(f\"Simulation finished, odb files generated.\\n\")\n",
    "    \n",
    "    return {\"output_files\": [os.path.join(working_directory, f) for f in outputs],\n",
    "            \"outputs_files_directory\": os.path.abspath(working_directory)}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"output_files\",\"outputs_files_directory\")\n",
    "def running_exe_in_compiler(macro, compiler_path, exe_path, base_path, directory_name,\n",
    "                            input_txt_paths_von_FAMOS=[], input_txt_paths_von_inp=[]):\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.write_exe_input = write_running_exe_input(compiler_path=compiler_path, \n",
    "                                                    exe_path=exe_path, \n",
    "                                                    working_directory=macro.work_dir,\n",
    "                                                    input_txt_paths_von_FAMOS=input_txt_paths_von_FAMOS,\n",
    "                                                    input_txt_paths_von_inp=input_txt_paths_von_inp)\n",
    "    macro.fortran_to_exe = run_exe(compiler_path=macro.write_exe_input[\"compiler_path\"], \n",
    "                                   exe_filename=macro.write_exe_input[\"exe_filename\"],\n",
    "                                   working_directory=macro.work_dir)\n",
    "\n",
    "    return (macro.fortran_to_exe[\"output_files\"],\n",
    "            macro.fortran_to_exe[\"outputs_files_directory\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33471497-372f-4087-b941-2c44fc86b4c4",
   "metadata": {},
   "source": [
    "#### Post-processing of Mechanical Simulation Results: Restart Detection, Join Compilation, and ODB Consolidation\n",
    "\n",
    "##### This post-processing block consolidates mechanical simulation outputs generated in multiple restart steps into a single continuous Abaqus `ODB` file.\n",
    "\n",
    "The workflow consists of three stages:\n",
    "\n",
    "1. Restart Detection and Initialization\n",
    "\n",
    "    - Identify the base mechanical ODB file.\n",
    "\n",
    "    - Detect all restart ODB files and determine the maximum iteration number.\n",
    "\n",
    "2. Adaptive Join Executable Generation\n",
    "\n",
    "    - Update the Fortran join source code with the detected restart count.\n",
    "\n",
    "    - Recompile the modified source to generate a new join.exe.\n",
    "\n",
    "3. ODB Merging\n",
    "\n",
    "    - Execute the join program in the compiler environment.\n",
    "\n",
    "    - Merge the base and restart ODB files into one final consolidated ODB.\n",
    "\n",
    "##### This ensures a consistent and automated reconstruction of the full mechanical simulation history from segmented restart outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9f023bf-cc2f-46ee-86c6-1a932693b3e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: Pre-processing, find the files number and change the name of basic file\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def processing_mech_files(working_directory):\n",
    "    index = 250822\n",
    "    find_mech_file = f\"{index}_MECH_START.odb\"\n",
    "    replace_mech_file = f\"{index}_MECH_JOINED.odb\"\n",
    "\n",
    "    find_path = os.path.join(working_directory, find_mech_file)\n",
    "    replace_path = os.path.join(working_directory, replace_mech_file)\n",
    "\n",
    "    if os.path.exists(find_path):\n",
    "        shutil.copy(find_path, replace_path)\n",
    "        print(f\"aimed odb file found und renamed a new file\")\n",
    "    else:\n",
    "        print(f\"aimed odb file does not exist\")\n",
    "\n",
    "    \n",
    "    pattern = re.compile(rf\"{index}_WPS_MECH_RESTART(\\d+)\\.odb$\")\n",
    "    max_num = -1\n",
    "    for filename in os.listdir(working_directory):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            number = int(match.group(1))\n",
    "            if number > max_num:\n",
    "                max_num = number\n",
    "\n",
    "    if max_num >= 0:\n",
    "        print(f\"maximal RESTART file number is: {max_num}\")\n",
    "    else:\n",
    "        print(f\"does not find RESTART file, please check the directory\")\n",
    "\n",
    "    return {\"Initialization\":replace_path,\n",
    "            \"Iteration_number\":max_num}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"Initialization\",\"Iteration_number\")\n",
    "def Mechfiles_number_and_rename_Mechfile(macro, working_directory):\n",
    "\n",
    "    macro.preprocessing_mech_files = processing_mech_files(working_directory=working_directory)\n",
    "\n",
    "    return (macro.preprocessing_mech_files[\"Initialization\"],\n",
    "            macro.preprocessing_mech_files[\"Iteration_number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2009f92-2eab-4771-b36b-30fd301627fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: Pre-processing, change the parameter(files number) in join.for and running in compiler, in order to get modified join.exe\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_join_input(compiler_path, fortran_join_path, working_directory, Iteration_number):\n",
    "    compiler_path = os.path.abspath(compiler_path)\n",
    "    fortran_join_path = os.path.abspath(fortran_join_path)\n",
    "\n",
    "    input_fortran_file = os.path.basename(fortran_join_path)   # Script name only (no path)\n",
    "    local_fortran_join_path = os.path.join(working_directory, input_fortran_file)   # Spell out the target path in the working directory\n",
    "    shutil.copy(fortran_join_path, local_fortran_join_path)\n",
    "\n",
    "    with open(local_fortran_join_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    updated_lines = []\n",
    "    Iteration_number = int(Iteration_number)\n",
    "    for line in lines:\n",
    "        if \"do i=0,\" in line.lower():\n",
    "            parts = line.split(\"do i=0,\")\n",
    "            old_fisrt = parts[0]\n",
    "            # old_second = parts[1]\n",
    "            new = f\"{old_fisrt}do i=0, {Iteration_number}\\n\"\n",
    "            updated_lines.append(new)\n",
    "        else:\n",
    "            updated_lines.append(line)\n",
    "\n",
    "    with open(local_fortran_join_path, \"w\") as f:\n",
    "        f.writelines(updated_lines)\n",
    "    \n",
    "\n",
    "    return {\"compiler_path\":compiler_path, \n",
    "            \"fortran_join_path\":local_fortran_join_path}\n",
    "\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def run_fortran_join_in_compiler(compiler_path, local_fortran_join_path, working_directory):\n",
    "    ## Parsing .lnk shortcuts (Windows)\n",
    "    with open(compiler_path, 'rb') as f:\n",
    "        lnk = pylnk3.parse(f)\n",
    "\n",
    "    raw_path = lnk.path.strip('\"')    # Executable path to which the shortcut points\n",
    "    raw_args = lnk.arguments.strip()    # Shortcut parameters\n",
    "\n",
    "    ## If .lnk points to cmd.exe, it is necessary to extract the .bat path from the parameter\n",
    "    if raw_path.lower().endswith(\"cmd.exe\"):\n",
    "        match = re.search(r'\"(?P<bat>C:.*?\\.bat)\"\\s*(?P<args>[^\"]*)', raw_args, re.IGNORECASE)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Unable to extract .bat file path from .lnk arguments with contents：{raw_args}\")\n",
    "        env_bat_path = match.group(\"bat\")\n",
    "        extra_args = match.group(\"args\")\n",
    "    else:\n",
    "        env_bat_path = raw_path\n",
    "        extra_args = raw_args\n",
    "\n",
    "    fortran_path = os.path.normpath(local_fortran_join_path)\n",
    "    compile_cmd = f'ifort \"{fortran_path}\"'\n",
    "\n",
    "    setup_cmd = f'call \"{env_bat_path}\" {extra_args} && {compile_cmd}'\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            f'cmd /c \"{setup_cmd}\"',\n",
    "            cwd=working_directory,\n",
    "            shell=True,\n",
    "            check=True,\n",
    "            text=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "        print(\"compiler output:\\n\", result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"warning:\\n\", result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"error\")\n",
    "        print(\"stdout:\\n\", e.stdout)\n",
    "        print(\"stderr:\\n\", e.stderr)\n",
    "        raise\n",
    "\n",
    "    exe_files = [f for f in os.listdir(working_directory) if f.lower().endswith(\".exe\")]\n",
    "    if not exe_files:\n",
    "        raise FileNotFoundError(\".exe file not found in the working directory\")\n",
    "\n",
    "    exe_filename = exe_files[0]\n",
    "    exe_path = os.path.abspath(os.path.join(working_directory, exe_filename))\n",
    "    \n",
    "    print(f\"Finish, generated file: ['{exe_filename}']\\n\")\n",
    "    \n",
    "    return {\"fortran_join_exe_filename\": exe_filename,\n",
    "            \"join_exe_path\": exe_path}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"fortran_join_exe_filename\", \"join_exe_path\")\n",
    "def fortran_join_to_exe(macro, compiler_path, fortran_join_path, base_path, directory_name, Iteration_number):\n",
    "    # path = macro.as_path() # This gives you the path based on the workflow name\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.fortran_join_file = write_join_input(compiler_path=compiler_path, \n",
    "                                               fortran_join_path=fortran_join_path, \n",
    "                                               working_directory=macro.work_dir,\n",
    "                                               Iteration_number=Iteration_number)\n",
    "    macro.fortran_join_to_exefile = run_fortran_join_in_compiler(compiler_path=macro.fortran_join_file[\"compiler_path\"], \n",
    "                                                             local_fortran_join_path=macro.fortran_join_file[\"fortran_join_path\"],\n",
    "                                                             working_directory=macro.work_dir)\n",
    "\n",
    "    return (macro.fortran_join_to_exefile[\"fortran_join_exe_filename\"],\n",
    "            macro.fortran_join_to_exefile[\"join_exe_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b2312ec-4584-4663-9409-d417bfe3e09d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Marco_node: join all .odb files from simulation\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def write_join_exe_input(compiler_path, exe_path, Initial_file_path, working_directory, input_odb_paths):\n",
    "    compiler_path = os.path.abspath(compiler_path)\n",
    "    exe_path = os.path.abspath(exe_path)\n",
    "    Initial_file_path = os.path.abspath(Initial_file_path)\n",
    "    \n",
    "    # Copy .exe to working directory\n",
    "    exe_filename = os.path.basename(exe_path)   # Script name only (no path)\n",
    "    local_exe_path = os.path.join(working_directory, exe_filename)   # Spell out the target path in the working directory\n",
    "    shutil.copy(exe_path, local_exe_path)\n",
    "\n",
    "    # Copy initial.odb to working directory\n",
    "    initial_odb_filename = os.path.basename(Initial_file_path)   # Script name only (no path)\n",
    "    local_initial_odb_path = os.path.join(working_directory, initial_odb_filename)   # Spell out the target path in the working directory\n",
    "    shutil.copy(Initial_file_path, local_initial_odb_path)\n",
    "    \n",
    "    # Copy all input odb files into working directory\n",
    "    local_odb_files = []\n",
    "    for odb_path in input_odb_paths:\n",
    "        odb_name = os.path.basename(odb_path)\n",
    "        dst_path = os.path.join(working_directory, odb_name)\n",
    "        odb_path = os.path.abspath(txt_path)\n",
    "        shutil.copy(odb_path, dst_path)\n",
    "        local_odb_files.append(dst_path)\n",
    "        \n",
    "    # print(local_txt_files)\n",
    "    \n",
    "    return {\"compiler_path\": compiler_path,\n",
    "            \"join_exe_filename\": join_exe_filename,\n",
    "            \"input_odb_set\": local_odb_files}\n",
    "\n",
    "\n",
    "@Workflow.wrap.as_function_node\n",
    "def run_join_exe(compiler_path, exe_filename, working_directory):\n",
    "    with open(compiler_path, 'rb') as f:\n",
    "        lnk = pylnk3.parse(f)\n",
    "\n",
    "    raw_path = lnk.path.strip('\"')\n",
    "    raw_args = lnk.arguments.strip()\n",
    "\n",
    "    if raw_path.lower().endswith(\"cmd.exe\"):\n",
    "        match = re.search(r'\"(?P<bat>C:.*?\\.bat)\"\\s*(?P<args>[^\"]*)', raw_args, re.IGNORECASE)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Unable to extract .bat file path from .lnk arguments with contents：{raw_args}\")\n",
    "        env_bat_path = match.group(\"bat\")\n",
    "        extra_args = match.group(\"args\").strip('\"')\n",
    "    else:\n",
    "        env_bat_path = raw_path\n",
    "        extra_args = raw_args\n",
    "        \n",
    "    ## First call the compiler environment variable\n",
    "    ## Then cd to the working directory\n",
    "    ## Finally, execute the .exe file\n",
    "    run_cmd = f'call \"{env_bat_path}\" {extra_args} && cd /d \"{working_directory}\" && \"{exe_filename}\"'\n",
    "\n",
    "    # print(f\"\\n{run_cmd}\\n\")\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            f'cmd /c \"{run_cmd}\"',\n",
    "            cwd=working_directory,\n",
    "            shell=True,\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        print(result.stdout)\n",
    "        print(result.stderr)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"error：\")\n",
    "        print(\"STDOUT:\\n\", e.stdout)\n",
    "        print(\"STDERR:\\n\", e.stderr)\n",
    "        raise\n",
    "\n",
    "    outputs = [f for f in os.listdir(working_directory) if f.endswith('.odb') and f == initial_odb_filename]\n",
    "    \n",
    "    print(f\"Joining finished, final odb files generated.\\n\")\n",
    "    \n",
    "    return {\"Final_odb_file_path\": [os.path.join(working_directory, f) for f in outputs]}\n",
    "\n",
    "\n",
    "### Run Marco_node\n",
    "@Workflow.wrap.as_macro_node(\"Final_odb_file_path\")\n",
    "def running_join_exe_in_compiler(macro, compiler_path, exe_path, base_path, \n",
    "                                 Initial_file_path, directory_name, input_odb_paths):\n",
    "    # path = macro.as_path() # This gives you the path based on the workflow name\n",
    "    path = base_path\n",
    "    macro.work_dir = generate_working_directory_overwrite(path, directory_name)\n",
    "    # macro.working_directory = generate_working_directory_keep(path)\n",
    "    macro.write_join_exe_input = write_join_exe_input(compiler_path=compiler_path, \n",
    "                                                      exe_path=exe_path, \n",
    "                                                      Initial_file_path=Initial_file_path,\n",
    "                                                      working_directory=macro.work_dir,\n",
    "                                                      input_odb_paths=input_odb_paths)\n",
    "    macro.fortran_join_to_exe = run_join_exe(compiler_path=macro.write_join_exe_input[\"compiler_path\"], \n",
    "                                             exe_filename=macro.write_join_exe_input[\"join_exe_filename\"],\n",
    "                                             working_directory=macro.work_dir)\n",
    "\n",
    "    return (macro.fortran_join_to_exe[\"Final_odb_file_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194b938-bc72-4c1f-8080-d40411278738",
   "metadata": {},
   "source": [
    "#### Integrated Local Simulation Workflow\n",
    "\n",
    "##### This block defines the complete automated simulation pipeline, linking geometry modification, Abaqus preprocessing, .inp processing, Fortran-based simulation, and final ODB merging into a structured local workflow.\n",
    "\n",
    "##### The execution depends on a properly configured local environment, including:\n",
    "\n",
    "1. Abaqus \n",
    "\n",
    "2. Intel Fortran compiler and environment setup\n",
    "\n",
    "3. Structured local directory and path management\n",
    "\n",
    "##### Since the workflow interacts directly with local executables and system paths, users must adapt file paths, compiler settings, and environment configurations according to their individual computer setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d0321ec-417e-490f-bfc1-819bf29e17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    wf = Workflow(\"Simulation_Workflow\")\n",
    "    wf.children.clear()\n",
    "    \n",
    "    project_path = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\AnAttAl_CAD_OnlyWorkflow_demo\"\n",
    "    abaqus_python_script = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\abaqusMacros.py\"\n",
    "    processing_inp_python_script = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\File_Programm2.py\"\n",
    "    fortran_compiler_path = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Compiler 16.0 Update 1 for Intel 64 Visual Studio 2015 environment.lnk\"\n",
    "    # fortran_file = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Testfall_1ms_Auskommentiert.for\" \n",
    "    fortran_file = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Testfall_1ms_Dyn5_a_a4.for\" \n",
    "    fortran_join_file = r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\odbjoin.for\"\n",
    "    input_txts_FAMOS = [r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Stromverlauf.txt\",\n",
    "                        r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Kraftverlauf.txt\",\n",
    "                        r\"C:\\Local_Dong\\Projekt\\AnAttAl\\CAD\\Potentialverlauf.txt\"]\n",
    "    \n",
    "    wf.Update_Geo_Abaqus = update_geometry_marco(original_abaqus_script=abaqus_python_script,\n",
    "                                                 working_directory=project_path)\n",
    "    \n",
    "    wf.Abaqus_Output = export_inp_cae(script_path=wf.Update_Geo_Abaqus.outputs[\"new_py_path\"], \n",
    "                                      base_path=project_path,\n",
    "                                      directory_name=\"Python_marco_to_inp\")\n",
    "    \n",
    "    wf.Processing_inp = processing_inp(script_path=processing_inp_python_script, \n",
    "                                       inp_path=wf.Abaqus_Output.outputs[\"inp_path\"], \n",
    "                                       base_path=project_path,\n",
    "                                       directory_name=\"Python_marco_processing_inp\")\n",
    "\n",
    "    wf.FAMOS_Output = FAMOS_Output(base_path=project_path,\n",
    "                                   directory_name=\"FAMOS_Output\",\n",
    "                                   input_txt_paths_von_FAMOS=input_txts_FAMOS)\n",
    "    \n",
    "    wf.Fortran_Executable_File = fortran_to_exe(compiler_path=fortran_compiler_path, \n",
    "                                                fortran_file_path=fortran_file, \n",
    "                                                base_path=project_path, \n",
    "                                                directory_name=\"Fortran_to_simulation_exe\")\n",
    "    \n",
    "    wf.Executing_File_in_compiler = running_exe_in_compiler(compiler_path=fortran_compiler_path,\n",
    "                                                            exe_path=wf.Fortran_Executable_File.outputs[\"exe_path\"],\n",
    "                                                            base_path=project_path,\n",
    "                                                            directory_name=\"running_exe_in_compiler\",\n",
    "                                                            input_txt_paths_von_FAMOS=wf.FAMOS_Output.outputs[\"FAMOS_txt\"],\n",
    "                                                            input_txt_paths_von_inp=wf.Processing_inp.outputs[\"txt_paths\"])\n",
    "\n",
    "    wf.Number_of_Iterations_and_Initialization = Mechfiles_number_and_rename_Mechfile(working_directory=wf.Executing_File_in_compiler.outputs[\"outputs_files_directory\"])\n",
    "\n",
    "    wf.Fortran_join_Executable_File = fortran_join_to_exe(compiler_path=fortran_compiler_path,\n",
    "                                                          fortran_join_path=fortran_join_file,\n",
    "                                                          base_path=project_path,\n",
    "                                                          directory_name=\"Fortran_to_join_exe\",\n",
    "                                                          Iteration_number=wf.Number_of_Iterations_and_Initialization.outputs[\"Iteration_number\"])\n",
    "\n",
    "    wf.Executing_join_in_compiler = running_join_exe_in_compiler(compiler_path=fortran_compiler_path,\n",
    "                                                                 input_odb_paths=wf.Executing_File_in_compiler.outputs[\"output_files\"],\n",
    "                                                                 base_path=project_path,\n",
    "                                                                 directory_name=\"executing_join_exe\",\n",
    "                                                                 exe_path=wf.Fortran_join_Executable_File.outputs[\"join_exe_path\"],\n",
    "                                                                 Initial_file_path=wf.Number_of_Iterations_and_Initialization.outputs[\"Initialization\"])\n",
    "\n",
    "    wf.draw(size=(10,10))\n",
    "    # wf.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf9b4d-5ea3-4e04-9abc-7b9c419cf6d4",
   "metadata": {},
   "source": [
    "#### Graphical Representation of the Integrated Simulation Workflow\n",
    "\n",
    "##### The diagram illustrates the complete simulation pipeline implemented in PyironFlow.\n",
    "\n",
    "##### The workflow sequentially connects geometry update, Abaqus preprocessing, .inp data extraction, FAMOS data import, Fortran-based simulation execution, and final mechanical ODB consolidation.\n",
    "\n",
    "##### All nodes are linked through structured dependencies, ensuring controlled data transfer, isolated working directories, and reproducible execution within a locally configured environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f2613ce-4da1-431c-9439-6f399413425c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8f721a69564828bcaa4cb19e6c8e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Accordion(children=(VBox(children=(Button(button_style='info', description='Refresh', style=But…"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    pf = PyironFlow([wf])\n",
    "    pf.gui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
